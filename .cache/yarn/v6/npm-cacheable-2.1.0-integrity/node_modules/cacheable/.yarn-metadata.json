{
  "manifest": {
    "name": "cacheable",
    "version": "2.1.0",
    "description": "High Performance Layer 1 / Layer 2 Caching with Keyv Storage",
    "type": "module",
    "main": "./dist/index.cjs",
    "module": "./dist/index.js",
    "types": "./dist/index.d.ts",
    "exports": {
      ".": {
        "require": "./dist/index.cjs",
        "import": "./dist/index.js"
      }
    },
    "repository": {
      "type": "git",
      "url": "git+https://github.com/jaredwray/cacheable.git",
      "directory": "packages/cacheable"
    },
    "author": {
      "name": "Jared Wray",
      "email": "me@jaredwray.com"
    },
    "license": "MIT",
    "private": false,
    "devDependencies": {
      "@biomejs/biome": "^2.2.4",
      "@faker-js/faker": "^10.0.0",
      "@keyv/redis": "^5.1.2",
      "@keyv/valkey": "^1.0.8",
      "@qified/redis": "^0.5.0",
      "@types/node": "^24.5.2",
      "@vitest/coverage-v8": "^3.2.4",
      "lru-cache": "^11.2.1",
      "rimraf": "^6.0.1",
      "tsup": "^8.5.0",
      "typescript": "^5.9.2",
      "vitest": "^3.2.4"
    },
    "dependencies": {
      "hookified": "^1.12.1",
      "keyv": "^5.5.3",
      "qified": "^0.5.0",
      "@cacheable/memoize": "^2.0.3",
      "@cacheable/memory": "^2.0.3",
      "@cacheable/utils": "^2.1.0"
    },
    "keywords": [
      "cacheable",
      "high performance",
      "layer 1 caching",
      "layer 2 caching",
      "distributed caching",
      "Keyv storage engine",
      "memory caching",
      "LRU cache",
      "expiration",
      "CacheableMemory",
      "offline support",
      "distributed sync",
      "secondary store",
      "primary store",
      "non-blocking operations",
      "cache statistics",
      "layered caching",
      "fault tolerant",
      "scalable cache",
      "in-memory cache",
      "distributed cache",
      "lruSize",
      "lru",
      "multi-tier cache"
    ],
    "files": [
      "dist",
      "LICENSE"
    ],
    "scripts": {
      "build": "rimraf ./dist && tsup src/index.ts --format cjs,esm --dts --clean --minify",
      "prepublish": "pnpm build",
      "lint": "biome check --write --error-on-warnings",
      "test": "pnpm lint && vitest run --coverage",
      "test:ci": "biome check --error-on-warnings && vitest run --coverage",
      "clean": "rimraf ./dist ./coverage ./node_modules"
    },
    "_registry": "npm",
    "_loc": "/home/container/.cache/yarn/v6/npm-cacheable-2.1.0-integrity/node_modules/cacheable/package.json",
    "readmeFilename": "README.md",
    "readme": "[<img align=\"center\" src=\"https://cacheable.org/logo.svg\" alt=\"Cacheable\" />](https://github.com/jaredwray/cacheable)\n\n> High Performance Layer 1 / Layer 2 Caching with Keyv Storage\n\n[![codecov](https://codecov.io/gh/jaredwray/cacheable/graph/badge.svg?token=lWZ9OBQ7GM)](https://codecov.io/gh/jaredwray/cacheable)\n[![tests](https://github.com/jaredwray/cacheable/actions/workflows/tests.yml/badge.svg)](https://github.com/jaredwray/cacheable/actions/workflows/tests.yml)\n[![npm](https://img.shields.io/npm/dm/cacheable.svg)](https://www.npmjs.com/package/cacheable)\n[![npm](https://img.shields.io/npm/v/cacheable)](https://www.npmjs.com/package/cacheable)\n[![license](https://img.shields.io/github/license/jaredwray/cacheable)](https://github.com/jaredwray/cacheable/blob/main/LICENSE)\n\n`cacheable` is a high performance layer 1 / layer 2 caching engine that is focused on distributed caching with enterprise features such as `CacheSync`. It is built on top of the robust storage engine [Keyv](https://keyv.org) and provides a simple API to cache and retrieve data.\n\n* Simple to use with robust API\n* Not bloated with additional modules\n* Scalable and trusted storage engine by Keyv\n* Memory Caching with LRU and Expiration `CacheableMemory`\n* Resilient to failures with try/catch and offline\n* Wrap / Memoization for Sync and Async Functions with Stampede Protection\n* Hooks and Events to extend functionality\n* Shorthand for ttl in milliseconds `(1m = 60000) (1h = 3600000) (1d = 86400000)`\n* Non-blocking operations for layer 2 caching\n* **Distributed Caching Sync via Pub/Sub with CacheSync**\n* Comprehensive testing and code coverage\n* ESM and CommonJS support with Typescript\n* Maintained and supported regularly\n\n# Table of Contents\n* [Getting Started](#getting-started)\n* [v1 to v2 Changes](#v1-to-v2-changes)\n* [Basic Usage](#basic-usage)\n* [Hooks and Events](#hooks-and-events)\n* [Storage Tiering and Caching](#storage-tiering-and-caching)\n* [TTL Propagation and Storage Tiering](#ttl-propagation-and-storage-tiering)\n* [Shorthand for Time to Live (ttl)](#shorthand-for-time-to-live-ttl)\n* [Non-Blocking Operations](#non-blocking-operations)\n* [Non-Blocking with @keyv/redis](#non-blocking-with-keyvredis)\n* [CacheableSync - Distributed Updates](#cacheablesync---distributed-updates)\n* [Cacheable Options](#cacheable-options)\n* [Cacheable Statistics (Instance Only)](#cacheable-statistics-instance-only)\n* [Cacheable - API](#cacheable---api)\n* [CacheableMemory - In-Memory Cache](#cacheablememory---in-memory-cache)\n* [Keyv Storage Adapter - KeyvCacheableMemory](#keyv-storage-adapter---keyvcacheablememory)\n* [Wrap / Memoization for Sync and Async Functions](#wrap--memoization-for-sync-and-async-functions)\n* [Get Or Set Memoization Function](#get-or-set-memoization-function)\n* [How to Contribute](#how-to-contribute)\n* [License and Copyright](#license-and-copyright)\n\n# Getting Started\n\n`cacheable` is primarily used as an extension to your caching engine with a robust storage backend [Keyv](https://keyv.org), Memoization (Wrap), Hooks, Events, and Statistics.\n\n```bash\nnpm install cacheable\n```\n\n# Basic Usage\n\n```javascript\nimport { Cacheable } from 'cacheable';\n\nconst cacheable = new Cacheable();\nawait cacheable.set('key', 'value', 1000);\nconst value = await cacheable.get('key');\n```\n\nThis is a basic example where you are only using the in-memory storage engine. To enable layer 1 and layer 2 caching you can use the `secondary` property in the options:\n\n```javascript\nimport { Cacheable } from 'cacheable';\nimport KeyvRedis from '@keyv/redis';\n\nconst secondary = new KeyvRedis('redis://user:pass@localhost:6379');\nconst cache = new Cacheable({secondary});\n``` \n\nIn this example, the primary store we will use `lru-cache` and the secondary store is Redis. You can also set multiple stores in the options:\n\n```javascript\nimport { Cacheable } from 'cacheable';\nimport { Keyv } from 'keyv';\nimport KeyvRedis from '@keyv/redis';\nimport { LRUCache } from 'lru-cache'\n\nconst primary = new Keyv({store: new LRUCache()});\nconst secondary = new KeyvRedis('redis://user:pass@localhost:6379');\nconst cache = new Cacheable({primary, secondary});\n```\n\nThis is a more advanced example and not needed for most use cases.\n\n# Hooks and Events\n\nThe following hooks are available for you to extend the functionality of `cacheable` via `CacheableHooks` enum:\n\n* `BEFORE_SET`: This is called before the `set()` method is called.\n* `AFTER_SET`: This is called after the `set()` method is called.\n* `BEFORE_SET_MANY`: This is called before the `setMany()` method is called.\n* `AFTER_SET_MANY`: This is called after the `setMany()` method is called.\n* `BEFORE_GET`: This is called before the `get()` method is called.\n* `AFTER_GET`: This is called after the `get()` method is called.\n* `BEFORE_GET_MANY`: This is called before the `getMany()` method is called.\n* `AFTER_GET_MANY`: This is called after the `getMany()` method is called.\n* `BEFORE_SECONDARY_SETS_PRIMARY`: This is called when the secondary store sets the value in the primary store.\n\nAn example of how to use these hooks:\n\n```javascript\nimport { Cacheable, CacheableHooks } from 'cacheable';\n\nconst cacheable = new Cacheable();\ncacheable.onHook(CacheableHooks.BEFORE_SET, (data) => {\n  console.log(`before set: ${data.key} ${data.value}`);\n});\n```\n\nHere is an example of how to use `BEFORE_SECONDARY_SETS_PRIMARY` hook:\n\n```javascript\nimport { Cacheable, CacheableHooks } from 'cacheable';\nimport KeyvRedis from '@keyv/redis';\nconst secondary = new KeyvRedis('redis://user:pass@localhost:6379');\nconst cache = new Cacheable({secondary});\ncache.onHook(CacheableHooks.BEFORE_SECONDARY_SETS_PRIMARY, (data) => {\n  console.log(`before secondary sets primary: ${data.key} ${data.value} ${data.ttl}`);\n});\n```\nThis is called when the secondary store sets the value in the primary store. This is useful if you want to do something before the value is set in the primary store such as manipulating the ttl or the value.\n\nThe following events are provided:\n\n- `error`: Emitted when an error occurs.\n- `cache:hit`: Emitted when a cache hit occurs.\n- `cache:miss`: Emitted when a cache miss occurs.\n\nHere is an example of using the `error` event:\n\n```javascript\nimport { Cacheable, CacheableEvents } from 'cacheable';\n\nconst cacheable = new Cacheable();\ncacheable.on(CacheableEvents.ERROR, (error) => {\n  console.error(`Cacheable error: ${error.message}`);\n});\n```\n\nWe also offer `cache:hit` and `cache:miss` events. These events are emitted when a cache hit or miss occurs, respectively. Here is how to use them:\n\n```javascript\nimport { Cacheable, CacheableEvents } from 'cacheable';\n\nconst cacheable = new Cacheable();\ncacheable.on(CacheableEvents.CACHE_HIT, (data) => {\n  console.log(`Cache hit: ${data.key} ${data.value} ${data.store}`); // the store will say primary or secondary\n});\ncacheable.on(CacheableEvents.CACHE_MISS, (data) => {\n  console.log(`Cache miss: ${data.key} ${data.store}`); // the store will say primary or secondary\n});\n```\n\n# Storage Tiering and Caching\n\n`cacheable` is built as a layer 1 and layer 2 caching engine by default. The purpose is to have your layer 1 be fast and your layer 2 be more persistent. The primary store is the layer 1 cache and the secondary store is the layer 2 cache. By adding the secondary store you are enabling layer 2 caching. By default the operations are blocking but fault tolerant:\n\n* `Setting Data`: Sets the value in the primary store and then the secondary store.\n* `Getting Data`: Gets the value from the primary if the value does not exist it will get it from the secondary store and set it in the primary store.\n* `Deleting Data`: Deletes the value from the primary store and secondary store at the same time waiting for both to respond.\n* `Clearing Data`: Clears the primary store and secondary store at the same time waiting for both to respond.\n\nWhen `Getting Data` if the value does not exist in the primary store it will try to get it from the secondary store. If the secondary store returns the value it will set it in the primary store. Because we use [TTL Propagation](#ttl-propagation-and-storage-tiering) the value will be set in the primary store with the TTL of the secondary store unless the time to live (TTL) is greater than the primary store which will then use the TTL of the primary store. An example of this is:\n\n```javascript\nimport { Cacheable } from 'cacheable';\nimport KeyvRedis from '@keyv/redis';\nconst secondary = new KeyvRedis('redis://user:pass@localhost:6379', { ttl: 1000 });\nconst cache = new Cacheable({secondary, ttl: 100});\n\nawait cache.set('key', 'value'); // sets the value in the primary store with a ttl of 100 ms and secondary store with a ttl of 1000 ms\n\nawait sleep(500); // wait for .5 seconds\n\nconst value = await cache.get('key'); // gets the value from the secondary store and now sets the value in the primary store with a ttl of 500 ms which is what is left from the secondary store\n```\n\nIn this example the primary store has a ttl of `100 ms` and the secondary store has a ttl of `1000 ms`. Because the ttl is greater in the secondary store it will default to setting ttl value in the primary store.\n\n```javascript\nimport { Cacheable } from 'cacheable';\nimport {Keyv} from 'keyv';\nimport KeyvRedis from '@keyv/redis';\nconst primary = new Keyv({ ttl: 200 });\nconst secondary = new KeyvRedis('redis://user:pass@localhost:6379', { ttl: 1000 });\nconst cache = new Cacheable({primary, secondary});\n\nawait cache.set('key', 'value'); // sets the value in the primary store with a ttl of 100 ms and secondary store with a ttl of 1000 ms\n\nawait sleep(200); // wait for .2 seconds\n\nconst value = await cache.get('key'); // gets the value from the secondary store and now sets the value in the primary store with a ttl of 200 ms which is what the primary store is set with\n```\n\n# TTL Propagation and Storage Tiering\n\nCacheable TTL propagation is a feature that allows you to set a time to live (TTL) for the cache. By default the TTL is set in the following order:\n\n```\nttl = set at the function ?? storage adapter ttl ?? cacheable ttl\n```\n\nThis means that if you set a TTL at the function level it will override the storage adapter TTL and the cacheable TTL. If you do not set a TTL at the function level it will use the storage adapter TTL and then the cacheable TTL. If you do not set a TTL at all it will use the default TTL of `undefined` which is disabled.\n\n# Shorthand for Time to Live (ttl)\n\nBy default `Cacheable` and `CacheableMemory` the `ttl` is in milliseconds but you can use shorthand for the time to live. Here are the following shorthand values:\n\n* `ms`: Milliseconds such as (1ms = 1)\n* `s`: Seconds such as (1s = 1000)\n* `m`: Minutes such as (1m = 60000)\n* `h` or `hr`: Hours such as (1h = 3600000)\n* `d`: Days such as (1d = 86400000)\n\nHere is an example of how to use the shorthand for the `ttl`:\n\n```javascript\nimport { Cacheable } from 'cacheable';\nconst cache = new Cacheable({ ttl: '15m' }); //sets the default ttl to 15 minutes (900000 ms)\ncache.set('key', 'value', '1h'); //sets the ttl to 1 hour (3600000 ms) and overrides the default\n```\n\nif you want to disable the `ttl` you can set it to `0` or `undefined`:\n\n```javascript\nimport { Cacheable } from 'cacheable';\nconst cache = new Cacheable({ ttl: 0 }); //sets the default ttl to 0 which is disabled\ncache.set('key', 'value', 0); //sets the ttl to 0 which is disabled\n```\n\nIf you set the ttl to anything below `0` or `undefined` it will disable the ttl for the cache and the value that returns will be `undefined`. With no ttl set the value will be stored `indefinitely`.\n\n```javascript\nimport { Cacheable } from 'cacheable';\nconst cache = new Cacheable({ ttl: 0 }); //sets the default ttl to 0 which is disabled\nconsole.log(cache.ttl); // undefined\ncache.ttl = '1h'; // sets the default ttl to 1 hour (3600000 ms)\nconsole.log(cache.ttl); // '1h'\ncache.ttl = -1; // sets the default ttl to 0 which is disabled\nconsole.log(cache.ttl); // undefined\n```\n\n## Retrieving raw cache entries\n\nThe `get` and `getMany` methods support a `raw` option, which returns the full stored metadata (`StoredDataRaw<T>`) instead of just the value:\n\n```typescript\nimport { Cacheable } from 'cacheable';\n\nconst cache = new Cacheable();\n\n// store a value\nawait cache.set('user:1', { name: 'Alice' });\n\n// default: only the value\nconst user = await cache.get<{ name: string }>('user:1');\nconsole.log(user); // { name: 'Alice' }\n\n// with raw: full record including expiration\nconst raw = await cache.get<{ name: string }>('user:1', { raw: true });\nconsole.log(raw.value);   // { name: 'Alice' }\nconsole.log(raw.expires); // e.g. 1677628495000 or null\n```\n\n```typescript\n// getMany with raw option\nawait cache.set('a', 1);\nawait cache.set('b', 2);\n\nconst raws = await cache.getMany<number>(['a', 'b'], { raw: true });\nraws.forEach((entry, idx) => {\n  console.log(`key=${['a','b'][idx]}, value=${entry?.value}, expires=${entry?.expires}`);\n});\n```\n\n\n# Non-Blocking Operations\n\nIf you want your layer 2 (secondary) store to be non-blocking you can set the `nonBlocking` property to `true` in the options. This will make the secondary store non-blocking and will not wait for the secondary store to respond on `setting data`, `deleting data`, or `clearing data`. This is useful if you want to have a faster response time and not wait for the secondary store to respond. Here is a full list of what each method does in nonBlocking mode:\n\n* `set` - in non-blocking mode it will set at the `primary` storage and then in the background update `secondary`\n* `get` - in non-blocking mode it will only check the primary storage but then in the background look to see if there is a value in the `secondary` and update the primary\n\n* `getMany` - in non-blocking mode it will only check the primary storage but then in the background look to see if there is a value in the `secondary` and update the primary\n\n* `getRaw` - in non-blocking mode it will only check the primary storage but then in the background look to see if there is a value in the `secondary` and update the primary\n\n* `getManyRaw` - in non-blocking mode it will only check the primary storage but then in the background look to see if there is a value in the `secondary` and update the primary\n\n# Non-Blocking with @keyv/redis\n\n`@keyv/redis` is one of the most popular storage adapters used with `cacheable`. It provides a Redis-backed cache store that can be used as a secondary store. It is a bit complicated to setup as by default it causes hangs and blocking with its default configuration. To get past this you will need to configure the following:\n\nConstruct your own Redis client via the `createClient()` method from `@keyv/redis` with the following options:\n* Set `disableOfflineQueue` to `true`\n* Set `socket.reconnectStrategy` to `false`\nIn the KeyvRedis options:\n* Set `throwOnConnectError` to `false`\nIn the Cacheable options:\n* Set `nonBlocking` to `true`\n\nWe have also build a function to help with this called `createKeyvNonBlocking` inside the `@keyv/redis` package after version `4.6.0`. Here is an example of how to use it:\n\n```javascript\nimport { Cacheable } from 'cacheable';\nimport { createKeyvNonBlocking } from '@keyv/redis';\n\nconst secondary = createKeyvNonBlocking('redis://user:pass@localhost:6379');\n\nconst cache = new Cacheable({ secondary, nonBlocking: true });\n```\n\n# GetOrSet\n\nThe `getOrSet` method provides a convenient way to implement the cache-aside pattern. It attempts to retrieve a value\nfrom cache, and if not found, calls the provided function to compute the value and store it in cache before returning\nit.\n\n```typescript\nimport { Cacheable } from 'cacheable';\n\n// Create a new Cacheable instance\nconst cache = new Cacheable();\n\n// Use getOrSet to fetch user data\nasync function getUserData(userId: string) {\n  return await cache.getOrSet(\n    `user:${userId}`,\n    async () => {\n      // This function only runs if the data isn't in the cache\n      console.log('Fetching user from database...');\n      // Simulate database fetch\n      return { id: userId, name: 'John Doe', email: 'john@example.com' };\n    },\n    { ttl: '30m' } // Cache for 30 minutes\n  );\n}\n\n// First call - will fetch from \"database\"\nconst user1 = await getUserData('123');\nconsole.log(user1); // { id: '123', name: 'John Doe', email: 'john@example.com' }\n\n// Second call - will retrieve from cache\nconst user2 = await getUserData('123');\nconsole.log(user2); // Same data, but retrieved from cache\n```\n\n```javascript\nimport { Cacheable } from 'cacheable';\nimport {KeyvRedis} from '@keyv/redis';\n\nconst secondary = new KeyvRedis('redis://user:pass@localhost:6379');\nconst cache = new Cacheable({secondary, nonBlocking: true});\n```\n\n# CacheableSync - Distributed Updates\n\n`cacheable` includes `CacheableSync`, a feature that enables distributed cache synchronization across multiple instances using Pub/Sub messaging via [Qified](https://github.com/jaredwray/qified). When a value is set or deleted in one cache instance, all other connected instances automatically receive and apply the update.\n\n## How It Works\n\n`CacheableSync` uses message providers from Qified to broadcast cache operations (SET and DELETE) to all connected cache instances. Each instance subscribes to these events and automatically updates its `primary` (example: in-memory) storage when receiving updates from other instances.\n\n## Supported Message Providers\n\n`Qified` supports multiple providers and you can learn more by going to https://qified.org.\n\n## Basic Usage\n\n```javascript\nimport { Cacheable } from 'cacheable';\nimport { RedisMessageProvider } from '@qified/redis';\n\n// Create a Redis message provider\nconst provider = new RedisMessageProvider({\n  connection: { host: 'localhost', port: 6379 }\n});\n\n// Create cache instances with sync enabled\nconst cache1 = new Cacheable({\n  sync: { qified: provider }\n});\n\nconst cache2 = new Cacheable({\n  sync: { qified: provider }\n});\n\n// Set a value in cache1\nawait cache1.set('key', 'value');\n\n// Note: you might want to sleep for a bit based on the backend.\n\n// The value is automatically synced to cache2\nconst value = await cache2.get('key'); // Returns 'value'\n```\n\n## Using Multiple Message Providers\n\nYou can use multiple message providers for redundancy:\n\n```javascript\nimport { Cacheable } from 'cacheable';\nimport { RedisMessageProvider } from '@qified/redis';\nimport { NatsMessageProvider } from '@qified/nats';\n\nconst redisProvider = new RedisMessageProvider({\n  connection: { host: 'localhost', port: 6379 }\n});\n\nconst natsProvider = new NatsMessageProvider({\n  servers: ['nats://localhost:4222']\n});\n\nconst cache = new Cacheable({\n  sync: { qified: [redisProvider, natsProvider] }\n});\n```\n\n## Using an Existing Qified Instance\n\nYou can also pass a pre-configured Qified instance:\n\n```javascript\nimport { Cacheable } from 'cacheable';\nimport { Qified } from 'qified';\nimport { RedisMessageProvider } from '@qified/redis';\n\nconst provider = new RedisMessageProvider({\n  connection: { host: 'localhost', port: 6379 }\n});\n\nconst qified = new Qified({ messageProviders: [provider] });\n\nconst cache = new Cacheable({\n  sync: { qified }\n});\n```\n\n## How Sync Works\n\n1. **SET Operations**: When you call `cache.set()` or `cache.setMany()`, the cache:\n   - Updates the local primary storage and secondary storage\n   - Publishes a `cache:set` event with the key, value, ttl, and cacheId\n   - Other cache instances receive the event and update their `primary` storage (excluding the originating instance)\n\n2. **DELETE Operations**: When you call `cache.delete()` or `cache.deleteMany()`, the cache:\n   - Removes the key from primary and secondary storage\n   - Publishes a `cache:delete` event with the key and cacheId\n   - Other cache instances receive the event and remove the key from their storage\n\n## Important Notes\n\n* Cache sync only works with the **primary storage layer**. Secondary storage is usually handled by the instance doing the initial work.\n* Each cache instance should have a unique `cacheId` to properly filter sync events. This is setup by default but you can set it if you want.\n* Sync events are **eventually consistent** - there may be a small delay between when a value is set and when it appears in other instances.\n* The sync feature requires a message provider to be running and accessible by all cache instances.\n* Each cache instance has a unique `cacheId`. Events are only applied if they come from a different instance, preventing infinite loops.\n\n# Cacheable Options\n\nThe following options are available for you to configure `cacheable`:\n\n* `primary`: The primary store for the cache (layer 1) defaults to in-memory by Keyv.\n* `secondary`: The secondary store for the cache (layer 2) usually a persistent cache by Keyv.\n* `nonBlocking`: If the secondary store is non-blocking. Default is `false`.\n* `stats`: To enable statistics for this instance. Default is `false`.\n* `ttl`: The default time to live for the cache in milliseconds. Default is `undefined` which is disabled.\n* `namespace`: The namespace for the cache. Default is `undefined`.\n* `cacheId`: A unique identifier for this cache instance. Used for sync filtering. Default is a random string.\n* `sync`: Enable distributed cache synchronization. Can be:\n  - `CacheableSync` instance\n  - `CacheableSyncOptions` object with `{ qified: MessageProvider | MessageProvider[] | Qified }`\n\n# Cacheable Statistics (Instance Only)\n\nIf you want to enable statistics for your instance you can set the `.stats.enabled` property to `true` in the options. This will enable statistics for your instance and you can get the statistics by calling the `stats` property. Here are the following property statistics:\n\n* `hits`: The number of hits in the cache.\n* `misses`: The number of misses in the cache.\n* `sets`: The number of sets in the cache.\n* `deletes`: The number of deletes in the cache.\n* `clears`: The number of clears in the cache.\n* `errors`: The number of errors in the cache.\n* `count`: The number of keys in the cache.\n* `vsize`: The estimated byte size of the values in the cache.\n* `ksize`: The estimated byte size of the keys in the cache.\n\nYou can clear / reset the stats by calling the `.stats.reset()` method.\n\n_This does not enable statistics for your layer 2 cache as that is a distributed cache_.\n\n# Cacheable - API\n\n* `set(key, value, ttl?)`: Sets a value in the cache.\n* `setMany([{key, value, ttl?}])`: Sets multiple values in the cache.\n* `get(key)`: Gets a value from the cache.\n* `get(key, { raw: true })`: Gets a raw value from the cache.\n* `getMany([keys])`: Gets multiple values from the cache.\n* `getMany([keys], { raw: true })`: Gets multiple raw values from the cache.\n* `has(key)`: Checks if a value exists in the cache.\n* `hasMany([keys])`: Checks if multiple values exist in the cache.\n* `take(key)`: Takes a value from the cache and deletes it.\n* `takeMany([keys])`: Takes multiple values from the cache and deletes them.\n* `delete(key)`: Deletes a value from the cache.\n* `deleteMany([keys])`: Deletes multiple values from the cache.\n* `clear()`: Clears the cache stores. Be careful with this as it will clear both layer 1 and layer 2.\n* `wrap(function, WrapOptions)`: Wraps an `async` function in a cache.\n* `getOrSet(GetOrSetKey, valueFunction, GetOrSetFunctionOptions)`: Gets a value from cache or sets it if not found using the provided function.\n* `disconnect()`: Disconnects from the cache stores.\n* `onHook(hook, callback)`: Sets a hook.\n* `removeHook(hook)`: Removes a hook.\n* `on(event, callback)`: Listens for an event.\n* `removeListener(event, callback)`: Removes a listener.\n* `hash(object: any, algorithm = 'sha256'): string`: Hashes an object with the algorithm. Default is `sha256`.\n* `primary`: The primary store for the cache (layer 1) defaults to in-memory by Keyv.\n* `secondary`: The secondary store for the cache (layer 2) usually a persistent cache by Keyv.\n* `namespace`: The namespace for the cache. Default is `undefined`. This will set the namespace for the primary and secondary stores.\n* `nonBlocking`: If the secondary store is non-blocking. Default is `false`.\n* `stats`: The statistics for this instance which includes `hits`, `misses`, `sets`, `deletes`, `clears`, `errors`, `count`, `vsize`, `ksize`.\n\n# CacheableMemory - In-Memory Cache\n\n`cacheable` comes with a built-in in-memory cache called `CacheableMemory` from `@cacheable/memory`. This is a simple in-memory cache that is used as the primary store for `cacheable`. You can use this as a standalone cache or as a primary store for `cacheable`. Here is an example of how to use `CacheableMemory`:\n\n```javascript\nimport { CacheableMemory } from 'cacheable';\nconst options = {\n  ttl: '1h', // 1 hour\n  useClones: true, // use clones for the values (default is true)\n  lruSize: 1000, // the size of the LRU cache (default is 0 which is unlimited)\n}\nconst cache = new CacheableMemory(options);\ncache.set('key', 'value');\nconst value = cache.get('key'); // value\n```\n\nTo learn more go to [@cacheable/memory](https://cacheable.org/docs/memory/)\n\n# Wrap / Memoization for Sync and Async Functions\n\n`Cacheable` and `CacheableMemory` has a feature called `wrap` that comes from [@cacheable/memoize](https://cacheable.org/docs/memoize/) and allows you to wrap a function in a cache. This is useful for memoization and caching the results of a function. You can wrap a `sync` or `async` function in a cache. Here is an example of how to use the `wrap` function:\n\n```javascript\nimport { Cacheable } from 'cacheable';\nconst asyncFunction = async (value: number) => {\n  return Math.random() * value;\n};\n\nconst cache = new Cacheable();\nconst options = {\n  ttl: '1h', // 1 hour\n  keyPrefix: 'p1', // key prefix. This is used if you have multiple functions and need to set a unique prefix.\n}\nconst wrappedFunction = cache.wrap(asyncFunction, options);\nconsole.log(await wrappedFunction(2)); // 4\nconsole.log(await wrappedFunction(2)); // 4 from cache\n```\nWith `Cacheable` we have also included stampede protection so that a `Promise` based call will only be called once if multiple requests of the same are executed at the same time. Here is an example of how to test for stampede protection:\n  \n```javascript\nimport { Cacheable } from 'cacheable';\nconst asyncFunction = async (value: number) => {\n  return value;\n};\n\nconst cache = new Cacheable();\nconst options = {\n  ttl: '1h', // 1 hour\n  keyPrefix: 'p1', // key prefix. This is used if you have multiple functions and need to set a unique prefix.\n}\n\nconst wrappedFunction = cache.wrap(asyncFunction, options);\nconst promises = [];\nfor (let i = 0; i < 10; i++) {\n  promises.push(wrappedFunction(i));\n}\n\nconst results = await Promise.all(promises); // all results should be the same\n\nconsole.log(results); // [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n```\n\nIn this example we are wrapping an `async` function in a cache with a `ttl` of `1 hour`. This will cache the result of the function for `1 hour` and then expire the value. You can also wrap a `sync` function in a cache:\n\n```javascript\nimport { CacheableMemory } from 'cacheable';\nconst syncFunction = (value: number) => {\n  return value * 2;\n};\n\nconst cache = new CacheableMemory();\nconst wrappedFunction = cache.wrap(syncFunction, { ttl: '1h', key: 'syncFunction' });\nconsole.log(wrappedFunction(2)); // 4\nconsole.log(wrappedFunction(2)); // 4 from cache\n```\n\nIn this example we are wrapping a `sync` function in a cache with a `ttl` of `1 hour`. This will cache the result of the function for `1 hour` and then expire the value. You can also set the `key` property in the `wrap()` options to set a custom key for the cache.\n\nWhen an error occurs in the function it will not cache the value and will return the error. This is useful if you want to cache the results of a function but not cache the error. If you want it to cache the error you can set the `cacheError` property to `true` in the `wrap()` options. This is disabled by default.\n\n```javascript\nimport { CacheableMemory } from 'cacheable';\nconst syncFunction = (value: number) => {\n  throw new Error('error');\n};\n\nconst cache = new CacheableMemory();\nconst wrappedFunction = cache.wrap(syncFunction, { ttl: '1h', key: 'syncFunction', cacheError: true });\nconsole.log(wrappedFunction()); // error\nconsole.log(wrappedFunction()); // error from cache\n```\n\nIf you would like to generate your own key for the wrapped function you can set the `createKey` property in the `wrap()` options. This is useful if you want to generate a key based on the arguments of the function or any other criteria.\n\n```javascript\n  const cache = new Cacheable();\n  const options: WrapOptions = {\n    cache,\n    keyPrefix: 'test',\n    createKey: (function_, arguments_, options: WrapOptions) => `customKey:${options?.keyPrefix}:${arguments_[0]}`,\n  };\n\n  const wrapped = wrap((argument: string) => `Result for ${argument}`, options);\n\n  const result1 = await wrapped('arg1');\n  const result2 = await wrapped('arg1'); // Should hit the cache\n\n  console.log(result1); // Result for arg1\n  console.log(result2); // Result for arg1 (from cache)\n```\n\nWe will pass in the `function` that is being wrapped, the `arguments` passed to the function, and the `options` used to wrap the function. You can then use these to generate a custom key for the cache.\n\nTo learn more visit [@cacheable/memoize](https://cacheable.org/docs/memoize/)\n\n# Get Or Set Memoization Function\n\nThe `getOrSet`  method that comes from [@cacheable/memoize](https://cacheable.org/docs/memoize/) provides a convenient way to implement the cache-aside pattern. It attempts to retrieve a value from cache, and if not found, calls the provided function to compute the value and store it in cache before returning it. Here are the options:\n\n```typescript\nexport type GetOrSetFunctionOptions = {\n\tttl?: number | string;\n\tcacheErrors?: boolean;\n\tthrowErrors?: boolean;\n};\n```\n\nHere is an example of how to use the `getOrSet` method:\n\n```javascript\nimport { Cacheable } from 'cacheable';\nconst cache = new Cacheable();\n// Use getOrSet to fetch user data\nconst function_ = async () => Math.random() * 100;\nconst value = await cache.getOrSet('randomValue', function_, { ttl: '1h' });\nconsole.log(value); // e.g. 42.123456789\n```\n\nYou can also use a function to compute the key for the function:\n\n```javascript\nimport { Cacheable, GetOrSetOptions } from 'cacheable';\nconst cache = new Cacheable();\n\n// Function to generate a key based on options\nconst generateKey = (options?: GetOrSetOptions) => {\n  return `custom_key_:${options?.cacheId || 'default'}`;\n};\n\nconst function_ = async () => Math.random() * 100;\nconst value = await cache.getOrSet(generateKey(), function_, { ttl: '1h' });\n```\n\nTo learn more go to [@cacheable/memoize](https://cacheable.org/docs/memoize/)\n\n# v1 to v2 Changes\n\n`cacheable` is now using `@cacheable/utils`, `@cacheable/memoize`, and `@cacheable/memory` for its core functionality as we are moving to this modular architecture and plan to eventually have these modules across `cache-manager` and `flat-cache`. In addition there are some breaking changes:\n\n* `get()` and `getMany()` no longer have the `raw` option but instead we have built out `getRaw()` and `getManyRaw()` to use.\n* All `get` related functions now support `nonBlocking` which means if `nonBlocking: true` the primary store will return what it has and then in the background will work to sync from secondary storage for any misses. You can disable this by setting at the `get` function level the option `nonBlocking: false` which will look for any missing keys in the secondary.\n* `Keyv` v5.5+ is now the recommended supported version as we are using its native `getMany*` and `getRaw*`\n* `Wrap` and `getOrSet` have been updated with more robust options including the ability to use your own `serialize` function for creating the key in `wrap`.\n* `hash` has now been updated with robust options and also an enum for setting the algorithm.\n\n# How to Contribute\n\nYou can contribute by forking the repo and submitting a pull request. Please make sure to add tests and update the documentation. To learn more about how to contribute go to our main README [https://github.com/jaredwray/cacheable](https://github.com/jaredwray/cacheable). This will talk about how to `Open a Pull Request`, `Ask a Question`, or `Post an Issue`.\n\n# License and Copyright\n[MIT © Jared Wray](./LICENSE)\n",
    "licenseText": "MIT License & © Jared Wray \n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to\ndeal in the Software without restriction, including without limitation the\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\nsell copies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\nDEALINGS IN THE SOFTWARE.\n"
  },
  "artifacts": [],
  "remote": {
    "resolved": "https://registry.npmjs.org/cacheable/-/cacheable-2.1.0.tgz",
    "type": "tarball",
    "reference": "https://registry.npmjs.org/cacheable/-/cacheable-2.1.0.tgz",
    "hash": "",
    "integrity": "sha512-zzL1BxdnqwD69JRT0dihnawAcLkBMwAH+hZSKjUzeBbPedVhk3qYPjRw9VOMYWwt5xRih5xd8S+3kEdGohZm/g==",
    "registry": "npm",
    "packageName": "cacheable",
    "cacheIntegrity": "sha512-zzL1BxdnqwD69JRT0dihnawAcLkBMwAH+hZSKjUzeBbPedVhk3qYPjRw9VOMYWwt5xRih5xd8S+3kEdGohZm/g== sha1-U5okpx0WMC0JY2cCu64atvt7FZs="
  },
  "registry": "npm",
  "hash": "cf32f5071767ab00faf49453d1d8a19dac0070b901330007fa16522a35337816cf79d561937a983e3470f5538c616c2de71462879c5df12fb7904746a21666fe"
}