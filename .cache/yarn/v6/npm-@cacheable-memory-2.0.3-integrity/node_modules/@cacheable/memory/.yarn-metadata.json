{
  "manifest": {
    "name": "@cacheable/memory",
    "version": "2.0.3",
    "description": "High Performance In-Memory Cache for Node.js",
    "type": "module",
    "main": "./dist/index.cjs",
    "module": "./dist/index.js",
    "types": "./dist/index.d.ts",
    "exports": {
      ".": {
        "require": "./dist/index.cjs",
        "import": "./dist/index.js"
      }
    },
    "repository": {
      "type": "git",
      "url": "git+https://github.com/jaredwray/cacheable.git",
      "directory": "packages/cacheable"
    },
    "author": {
      "name": "Jared Wray",
      "email": "me@jaredwray.com"
    },
    "license": "MIT",
    "private": false,
    "devDependencies": {
      "@biomejs/biome": "^2.2.4",
      "@faker-js/faker": "^10.0.0",
      "@types/node": "^24.5.2",
      "@vitest/coverage-v8": "^3.2.4",
      "rimraf": "^6.0.1",
      "tsup": "^8.5.0",
      "typescript": "^5.9.2",
      "vitest": "^3.2.4"
    },
    "dependencies": {
      "@keyv/bigmap": "^1.0.2",
      "hookified": "^1.12.1",
      "keyv": "^5.5.3",
      "@cacheable/memoize": "^2.0.3",
      "@cacheable/utils": "^2.0.3"
    },
    "keywords": [
      "cacheable",
      "high performance",
      "distributed caching",
      "Keyv storage engine",
      "keyv",
      "memory caching",
      "LRU cache",
      "memory",
      "in-memory",
      "scalable cache",
      "in-memory cache",
      "lruSize",
      "lru"
    ],
    "files": [
      "dist",
      "LICENSE"
    ],
    "scripts": {
      "build": "rimraf ./dist && tsup src/index.ts --format cjs,esm --dts --clean --minify",
      "prepublish": "pnpm build",
      "lint": "biome check --write --error-on-warnings",
      "test": "pnpm lint && vitest run --coverage",
      "test:ci": "biome check --error-on-warnings && vitest run --coverage",
      "clean": "rimraf ./dist ./coverage ./node_modules"
    },
    "_registry": "npm",
    "_loc": "/home/container/.cache/yarn/v6/npm-@cacheable-memory-2.0.3-integrity/node_modules/@cacheable/memory/package.json",
    "readmeFilename": "README.md",
    "readme": "[<img align=\"center\" src=\"https://cacheable.org/logo.svg\" alt=\"Cacheable\" />](https://github.com/jaredwray/cacheable)\n\n> High Performance Layer 1 / Layer 2 Caching with Keyv Storage\n\n[![codecov](https://codecov.io/gh/jaredwray/cacheable/graph/badge.svg?token=lWZ9OBQ7GM)](https://codecov.io/gh/jaredwray/cacheable)\n[![tests](https://github.com/jaredwray/cacheable/actions/workflows/tests.yml/badge.svg)](https://github.com/jaredwray/cacheable/actions/workflows/tests.yml)\n[![npm](https://img.shields.io/npm/dm/@cacheable/memory.svg)](https://www.npmjs.com/package/@cacheable/memory)\n[![npm](https://img.shields.io/npm/v/@cacheable/memory.svg)](https://www.npmjs.com/package/@cacheable/memory)\n[![license](https://img.shields.io/github/license/jaredwray/cacheable)](https://github.com/jaredwray/cacheable/blob/main/LICENSE)\n\nYou can use `CacheableMemory` as a standalone cache or as a primary store for `cacheable`. You can also set the `useClones` property to `false` if you want to use the same reference for the values. This is useful if you are using large objects and want to save memory. The `lruSize` property is the size of the LRU cache and is set to `0` by default which is unlimited. When setting the `lruSize` property it will limit the number of keys in the cache.\n\nThis simple in-memory cache uses multiple Map objects and a with `expiration` and `lru` policies if set to manage the in memory cache at scale.\n\nBy default we use lazy expiration deletion which means on `get` and `getMany` type functions we look if it is expired and then delete it. If you want to have a more aggressive expiration policy you can set the `checkInterval` property to a value greater than `0` which will check for expired keys at the interval you set.\n\nHere are some of the main features of `CacheableMemory`:\n* High performance in-memory cache with a robust API and feature set. ðŸš€\n* Can scale past the `16,777,216 (2^24) keys` limit of a single `Map` via `hashStoreSize`. Default is `16` Map objects.\n* LRU (Least Recently Used) cache feature to limit the number of keys in the cache via `lruSize`. Limit to `16,777,216 (2^24) keys` total.\n* Expiration policy to delete expired keys with lazy deletion or aggressive deletion via `checkInterval`.\n* `Wrap` feature to memoize `sync` and `async` functions with stampede protection.\n* Ability to do many operations at once such as `setMany`, `getMany`, `deleteMany`, and `takeMany`.\n* Supports `raw` data retrieval with `getRaw` and `getManyRaw` methods to get the full metadata of the cache entry.\n\n# Table of Contents\n* [Getting Started](#getting-started)\n* [CacheableMemory - In-Memory Cache](#cacheablememory---in-memory-cache)\n* [CacheableMemory Store Hashing](#cacheablememory-store-hashing)\n* [CacheableMemory LRU Feature](#cacheablememory-lru-feature)\n* [CacheableMemory Performance](#cacheablememory-performance)\n* [CacheableMemory Options](#cacheablememory-options)\n* [CacheableMemory - API](#cacheablememory---api)\n* [Keyv Storage Adapter - KeyvCacheableMemory](#keyv-storage-adapter---keyvcacheablememory)\n* [Wrap / Memoization for Sync and Async Functions](#wrap--memoization-for-sync-and-async-functions)\n* [Get Or Set Memoization Function](#get-or-set-memoization-function)\n* [How to Contribute](#how-to-contribute)\n* [License and Copyright](#license-and-copyright)\n\n# Getting Started\n\n```bash\nnpm install @cacheable/memory\n```\n\n# Basic Usage\n\n```javascript\nimport { CacheableMemory } from '@cacheable/memory';\n\nconst cacheable = new CacheableMemory();\nawait cacheable.set('key', 'value', 1000);\nconst value = await cacheable.get('key');\n```\n\nIn this example, the primary store we will use `lru-cache` and the secondary store is Redis. You can also set multiple stores in the options:\n\n```javascript\nimport { CacheableMemory } from '@cacheable/memory';\n\n// we set the storeHashSize to 1 so that we only use a single Map object as the lru is limited to a single Map size\nconst cache = new CacheableMemory({storeHashSize: 1, lruSize: 80000});\n\ncache.set('key1', 'value1');\nconst result = cache.get('key1');\nconsole.log(result); // 'value1' \n```\n\nThis is a more advanced example and not needed for most use cases.\n\n# Shorthand for Time to Live (ttl)\n\nBy default `Cacheable` and `CacheableMemory` the `ttl` is in milliseconds but you can use shorthand for the time to live. Here are the following shorthand values:\n\n* `ms`: Milliseconds such as (1ms = 1)\n* `s`: Seconds such as (1s = 1000)\n* `m`: Minutes such as (1m = 60000)\n* `h` or `hr`: Hours such as (1h = 3600000)\n* `d`: Days such as (1d = 86400000)\n\nHere is an example of how to use the shorthand for the `ttl`:\n\n```javascript\nimport { CacheableMemory } from 'cacheable';\nconst cache = new CacheableMemory({ ttl: '15m' }); //sets the default ttl to 15 minutes (900000 ms)\ncache.set('key', 'value', '1h'); //sets the ttl to 1 hour (3600000 ms) and overrides the default\n```\n\nif you want to disable the `ttl` you can set it to `0` or `undefined`:\n\n```javascript\nimport { CacheableMemory } from 'cacheable';\nconst cache = new CacheableMemory({ ttl: 0 }); //sets the default ttl to 0 which is disabled\ncache.set('key', 'value', 0); //sets the ttl to 0 which is disabled\n```\n\nIf you set the ttl to anything below `0` or `undefined` it will disable the ttl for the cache and the value that returns will be `undefined`. With no ttl set the value will be stored `indefinitely`.\n\n```javascript\nimport { CacheableMemory } from 'cacheable';\nconst cache = new CacheableMemory({ ttl: 0 }); //sets the default ttl to 0 which is disabled\nconsole.log(cache.ttl); // undefined\ncache.ttl = '1h'; // sets the default ttl to 1 hour (3600000 ms)\nconsole.log(cache.ttl); // '1h'\ncache.ttl = -1; // sets the default ttl to 0 which is disabled\nconsole.log(cache.ttl); // undefined\n```\n\n## Retrieving raw cache entries\n\nThe `getRaw` and `getManyRaw` methods return the full stored metadata (`StoredDataRaw<T>`) instead of just the value:\n\n```typescript\nimport { CacheableMemory } from 'cacheable';\n\nconst cache = new CacheableMemory();\n\n// store a value\nawait cache.set('user:1', { name: 'Alice' }, '1h'); // 1 hour\n\n// default: only the value\nconst user = await cache.get<{ name: string }>('user:1');\nconsole.log(user); // { name: 'Alice' }\n\n// with raw: full record including expiration\nconst raw = await cache.getRaw('user:1');\nconsole.log(raw.value);   // { name: 'Alice' }\nconsole.log(raw.expires); // e.g. 1677628495000 or null\n```\n\n## CacheableMemory Store Hashing\n\n`CacheableMemory` uses `Map` objects to store the keys and values. To make this scale past the `16,777,216 (2^24) keys` limit of a single `Map` we use a hash to balance the data across multiple `Map` objects. This is done by hashing the key and using the hash to determine which `Map` object to use. The default hashing algorithm is `djb2Hash` but you can change it by setting the `storeHashAlgorithm` property in the options. By default we set the amount of `Map` objects to `16`. \n\nNOTE: if you are using the LRU cache feature the `lruSize` no matter how many `Map` objects you have it will be limited to the `16,777,216 (2^24) keys` limit of a single `Map` object. This is because we use a double linked list to manage the LRU cache and it is not possible to have more than `16,777,216 (2^24) keys` in a single `Map` object.\n\nHere is an example of how to set the number of `Map` objects and the hashing algorithm:\n\n```javascript\nimport { CacheableMemory } from '@cacheable/memory';\nconst cache = new CacheableMemory({\n  storeSize: 32, // set the number of Map objects to 32\n});\ncache.set('key', 'value');\nconst value = cache.get('key'); // value\n```\n\nHere is an example of how to use the `storeHashAlgorithm` property:\n\n```javascript\nimport { CacheableMemory } from '@cacheable/memory';\nconst cache = new CacheableMemory({ storeHashAlgorithm: 'sha256' });\ncache.set('key', 'value');\nconst value = cache.get('key'); // value\n```\n\nIf you want to provide your own hashing function you can set the `storeHashAlgorithm` property to a function that takes an object and returns a `number` that is in the range of the amount of `Map` stores you have.\n\n```javascript\nimport { CacheableMemory } from '@cacheable/memory';\nconst cache = new CacheableMemory({ storeHashAlgorithm: HashAlgorithm.SHA256 });\ncache.set('key', 'value');\nconst value = cache.get('key'); // value\n```\n\nIf you want to provide your own hashing function you can set the `storeHashAlgorithm` property to a function that takes an object and returns a `number` that is in the range of the amount of `Map` stores you have.\n\n```javascript\nimport { CacheableMemory } from 'cacheable';\n/**\n * Custom hash function that takes a key and the size of the store\n * and returns a number between 0 and storeHashSize - 1.\n * @param {string} key - The key to hash.\n * @param {number} storeHashSize - The size of the store (number of Map objects).\n * @returns {number} - A number between 0 and storeHashSize - 1.\n */\nconst customHash = (key, storeHashSize) => {\n  // custom hashing logic\n  return key.length % storeHashSize; // returns a number between 0 and 31 for 32 Map objects\n};\nconst cache = new CacheableMemory({ storeHashAlgorithm: customHash, storeSize: 32 });\ncache.set('key', 'value');\nconst value = cache.get('key'); // value\n```\n\n## CacheableMemory LRU Feature\n\nYou can enable the LRU (Least Recently Used) feature in `CacheableMemory` by setting the `lruSize` property in the options. This will limit the number of keys in the cache to the size you set. When the cache reaches the limit it will remove the least recently used keys from the cache. This is useful if you want to limit the memory usage of the cache.\n\nWhen you set the `lruSize` we use a double linked list to manage the LRU cache and also set the `hashStoreSize` to `1` which means we will only use a single `Map` object for the LRU cache. This is because the LRU cache is managed by the double linked list and it is not possible to have more than `16,777,216 (2^24) keys` in a single `Map` object.\n\n```javascript\nimport { CacheableMemory } from 'cacheable';\nconst cache = new CacheableMemory({ lruSize: 1 }); // sets the LRU cache size to 1000 keys and hashStoreSize to 1\ncache.set('key1', 'value1');\ncache.set('key2', 'value2');\nconst value1 = cache.get('key1');\nconsole.log(value1); // undefined if the cache is full and key1 is the least recently used\nconst value2 = cache.get('key2');\nconsole.log(value2); // value2 if key2 is still in the cache\nconsole.log(cache.size()); // 1\n```\n\nNOTE: if you set the `lruSize` property to `0` after it was enabled it will disable the LRU cache feature and will not limit the number of keys in the cache. This will remove the `16,777,216 (2^24) keys` limit of a single `Map` object and will allow you to store more keys in the cache.\n\n## CacheableMemory Performance\n\nOur goal with `cacheable` and `CacheableMemory` is to provide a high performance caching engine that is simple to use and has a robust API. We test it against other cacheing engines such that are less feature rich to make sure there is little difference. Here are some of the benchmarks we have run:\n\n*Memory Benchmark Results:*\n|                   name                   |  summary  |  ops/sec  |  time/op  |  margin  |  samples  |\n|------------------------------------------|:---------:|----------:|----------:|:--------:|----------:|\n|  Cacheable Memory (v1.10.0) - set / get  |    ðŸ¥‡     |     152K  |      7Âµs  |  Â±0.94%  |     147K  |\n|  Map (v22) - set / get                   |   -1.1%   |     151K  |      7Âµs  |  Â±0.69%  |     145K  |\n|  Node Cache - set / get                  |   -4.3%   |     146K  |      7Âµs  |  Â±1.13%  |     142K  |\n|  bentocache (v1.4.0) - set / get         |   -20%    |     121K  |      8Âµs  |  Â±0.40%  |     119K  |\n\n*Memory LRU Benchmark Results:*\n|                   name                   |  summary  |  ops/sec  |  time/op  |  margin  |  samples  |\n|------------------------------------------|:---------:|----------:|----------:|:--------:|----------:|\n|  quick-lru (v7.0.1) - set / get          |    ðŸ¥‡     |     118K  |      9Âµs  |  Â±0.85%  |     112K  |\n|  Map (v22) - set / get                   |  -0.56%   |     117K  |      9Âµs  |  Â±1.35%  |     110K  |\n|  lru.min (v1.1.2) - set / get            |   -1.7%   |     116K  |      9Âµs  |  Â±0.90%  |     110K  |\n|  Cacheable Memory (v1.10.0) - set / get  |   -3.3%   |     114K  |      9Âµs  |  Â±1.16%  |     108K  |\n\nAs you can see from the benchmarks `CacheableMemory` is on par with other caching engines such as `Map`, `Node Cache`, and `bentocache`. We have also tested it against other LRU caching engines such as `quick-lru` and `lru.min` and it performs well against them too.\n\n## CacheableMemory Options\n\n* `ttl`: The time to live for the cache in milliseconds. Default is `undefined` which is means indefinitely.\n* `useClones`: If the cache should use clones for the values. Default is `true`.\n* `lruSize`: The size of the LRU cache. Default is `0` which is unlimited.\n* `checkInterval`: The interval to check for expired keys in milliseconds. Default is `0` which is disabled.\n* `storeHashSize`: The number of `Map` objects to use for the cache. Default is `16`.\n* `storeHashAlgorithm`: The hashing algorithm to use for the cache. Default is `djb2Hash`.\n\n## CacheableMemory - API\n\n* `set(key, value, ttl?)`: Sets a value in the cache.\n* `setMany([{key, value, ttl?}])`: Sets multiple values in the cache from `CacheableItem`.\n* `get(key)`: Gets a value from the cache.\n* `getMany([keys])`: Gets multiple values from the cache.\n* `getRaw(key)`: Gets a value from the cache as `CacheableStoreItem`.\n* `getManyRaw([keys])`: Gets multiple values from the cache as `CacheableStoreItem`.\n* `has(key)`: Checks if a value exists in the cache.\n* `hasMany([keys])`: Checks if multiple values exist in the cache.\n* `delete(key)`: Deletes a value from the cache.\n* `deleteMany([keys])`: Deletes multiple values from the cache.\n* `take(key)`: Takes a value from the cache and deletes it.\n* `takeMany([keys])`: Takes multiple values from the cache and deletes them.\n* `wrap(function, WrapSyncOptions)`: Wraps a `sync` function in a cache.\n* `clear()`: Clears the cache.\n* `ttl`: The default time to live for the cache in milliseconds. Default is `undefined` which is disabled.\n* `useClones`: If the cache should use clones for the values. Default is `true`.\n* `lruSize`: The size of the LRU cache. Default is `0` which is unlimited.\n* `size`: The number of keys in the cache.\n* `checkInterval`: The interval to check for expired keys in milliseconds. Default is `0` which is disabled.\n* `storeHashSize`: The number of `Map` objects to use for the cache. Default is `16`.\n* `storeHashAlgorithm`: The hashing algorithm to use for the cache. Default is `djb2Hash`.\n* `keys`: Get the keys in the cache. Not able to be set.\n* `items`: Get the items in the cache as `CacheableStoreItem` example `{ key, value, expires? }`.\n* `store`: The hash store for the cache which is an array of `Map` objects.\n* `checkExpired()`: Checks for expired keys in the cache. This is used by the `checkInterval` property.\n* `startIntervalCheck()`: Starts the interval check for expired keys if `checkInterval` is above 0 ms.\n* `stopIntervalCheck()`: Stops the interval check for expired keys.\n\n# Keyv Storage Adapter - KeyvCacheableMemory\n\n`cacheable` comes with a built-in storage adapter for Keyv called `KeyvCacheableMemory`. This takes `CacheableMemory` and creates a storage adapter for Keyv. This is useful if you want to use `CacheableMemory` as a storage adapter for Keyv. Here is an example of how to use `KeyvCacheableMemory`:\n\n```javascript\nimport { Keyv } from 'keyv';\nimport { KeyvCacheableMemory } from 'cacheable';\n\nconst keyv = new Keyv({ store: new KeyvCacheableMemory() });\nawait keyv.set('foo', 'bar');\nconst value = await keyv.get('foo');\nconsole.log(value); // bar \n```\n\n# Wrap / Memoization for Sync and Async Functions\n\n`CacheableMemory` has a feature called `wrap` that allows you to wrap a function in a cache. This is useful for memoization and caching the results of a function. You can wrap a `sync` function in a cache. Here is an example of how to use the `wrap` function:\n\n```javascript\nimport { CacheableMemory } from 'cacheable';\nconst syncFunction = (value: number) => {\n  return value * 2;\n};\n\nconst cache = new CacheableMemory();\nconst wrappedFunction = cache.wrap(syncFunction, { ttl: '1h', key: 'syncFunction' });\nconsole.log(wrappedFunction(2)); // 4\nconsole.log(wrappedFunction(2)); // 4 from cache\n```\n\nIn this example we are wrapping a `sync` function in a cache with a `ttl` of `1 hour`. This will cache the result of the function for `1 hour` and then expire the value. You can also set the `key` property in the `wrap()` options to set a custom key for the cache.\n\nWhen an error occurs in the function it will not cache the value and will return the error. This is useful if you want to cache the results of a function but not cache the error. If you want it to cache the error you can set the `cacheError` property to `true` in the `wrap()` options. This is disabled by default.\n\n```javascript\nimport { CacheableMemory } from 'cacheable';\nconst syncFunction = (value: number) => {\n  throw new Error('error');\n};\n\nconst cache = new CacheableMemory();\nconst wrappedFunction = cache.wrap(syncFunction, { ttl: '1h', key: 'syncFunction', cacheError: true });\nconsole.log(wrappedFunction()); // error\nconsole.log(wrappedFunction()); // error from cache\n```\n\nIf you would like to generate your own key for the wrapped function you can set the `createKey` property in the `wrap()` options. This is useful if you want to generate a key based on the arguments of the function or any other criteria.\n\n```javascript\n  const cache = new CacheableMemory();\n  const options: WrapOptions = {\n    cache,\n    keyPrefix: 'test',\n    createKey: (function_, arguments_, options: WrapOptions) => `customKey:${options?.keyPrefix}:${arguments_[0]}`,\n  };\n\n  const wrapped = wrap((argument: string) => `Result for ${argument}`, options);\n\n  const result1 = wrapped('arg1');\n  const result2 = wrapped('arg1'); // Should hit the cache\n\n  console.log(result1); // Result for arg1\n  console.log(result2); // Result for arg1 (from cache)\n```\n\nWe will pass in the `function` that is being wrapped, the `arguments` passed to the function, and the `options` used to wrap the function. You can then use these to generate a custom key for the cache.\n\n# How to Contribute\n\nYou can contribute by forking the repo and submitting a pull request. Please make sure to add tests and update the documentation. To learn more about how to contribute go to our main README [https://github.com/jaredwray/cacheable](https://github.com/jaredwray/cacheable). This will talk about how to `Open a Pull Request`, `Ask a Question`, or `Post an Issue`.\n\n# License and Copyright\n[MIT Â© Jared Wray](./LICENSE)\n",
    "licenseText": "MIT License & Â© Jared Wray \n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to\ndeal in the Software without restriction, including without limitation the\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\nsell copies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\nDEALINGS IN THE SOFTWARE.\n"
  },
  "artifacts": [],
  "remote": {
    "resolved": "https://registry.npmjs.org/@cacheable/memory/-/memory-2.0.3.tgz",
    "type": "tarball",
    "reference": "https://registry.npmjs.org/@cacheable/memory/-/memory-2.0.3.tgz",
    "hash": "",
    "integrity": "sha512-R3UKy/CKOyb1LZG/VRCTMcpiMDyLH7SH3JrraRdK6kf3GweWCOU3sgvE13W3TiDRbxnDKylzKJvhUAvWl9LQOA==",
    "registry": "npm",
    "packageName": "@cacheable/memory",
    "cacheIntegrity": "sha512-R3UKy/CKOyb1LZG/VRCTMcpiMDyLH7SH3JrraRdK6kf3GweWCOU3sgvE13W3TiDRbxnDKylzKJvhUAvWl9LQOA== sha1-jY+hZEsyuF8nx+ThbhTzaoRgc1w="
  },
  "registry": "npm",
  "hash": "47750acbf08a3b26f52d91bf55109331ca62303c8b1fb487dc9aeb69174aea47f71b079608e537b20bc4d775b74e20d16f19c32b2973289be1500bd697d2d038"
}