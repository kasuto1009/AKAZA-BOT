{
  "manifest": {
    "name": "cache-manager",
    "version": "5.7.6",
    "description": "Cache module for Node.js",
    "main": "dist/index.js",
    "types": "dist/index.d.ts",
    "files": [
      "dist/**/*.js",
      "dist/**/*.d.ts",
      "LISCENCE"
    ],
    "engines": {
      "node": ">= 18"
    },
    "repository": {
      "type": "git",
      "url": "https://github.com/jaredwray/cacheable.git"
    },
    "keywords": [
      "cache",
      "redis",
      "lru-cache",
      "memory cache",
      "multiple cache"
    ],
    "authors": [
      {
        "name": "Jared Wray",
        "email": "me@jaredwray.com"
      },
      {
        "name": "Bryan Donovan"
      },
      {
        "name": "Juan Aguilar Santillana",
        "email": "mhpoin@gmail.com"
      }
    ],
    "license": "MIT",
    "dependencies": {
      "eventemitter3": "^5.0.1",
      "lodash.clonedeep": "^4.5.0",
      "lru-cache": "^10.2.2",
      "promise-coalesce": "^1.1.2"
    },
    "devDependencies": {
      "@faker-js/faker": "^8.4.1",
      "@types/lodash.clonedeep": "^4.5.9",
      "@types/node": "^22.0.0",
      "@typescript-eslint/eslint-plugin": "^7.17.0",
      "@typescript-eslint/parser": "^7.17.0",
      "@vitest/coverage-v8": "^2.0.5",
      "eslint-config-xo-typescript": "^5.0.0",
      "rimraf": "^6.0.1",
      "typescript": "^5.5.4",
      "vitest": "^2.0.5",
      "xo": "^0.59.3"
    },
    "xo": {
      "extends": "xo-typescript",
      "extensions": [
        "ts",
        "tsx"
      ],
      "rules": {
        "@typescript-eslint/use-unknown-in-catch-callback-variable": "off",
        "promise/prefer-await-to-then": "off",
        "no-promise-executor-return promise/param-names": "off",
        "promise/param-names": "off",
        "no-promise-executor-return": "off",
        "@typescript-eslint/only-throw-error": "off",
        "promise/valid-params": "off",
        "n/file-extension-in-import": "off"
      }
    },
    "scripts": {
      "build": "rimraf ./dist && tsc -p tsconfig.build.json",
      "clean": "rimraf ./dist ./coverage ./node_modules ./package-lock.json ./yarn.lock ./pnpm-lock.yaml",
      "test": "xo --fix && vitest run --coverage",
      "test:ci": "xo && vitest run"
    },
    "_registry": "npm",
    "_loc": "/home/container/.cache/yarn/v6/npm-cache-manager-5.7.6-bdd8a154c73e5233824aa09ceb359ed225d37b7e-integrity/node_modules/cache-manager/package.json",
    "readmeFilename": "README.md",
    "readme": "[<img align=\"center\" src=\"https://jaredwray.com/images/cacheable_white.svg\" alt=\"keyv\">](https://github.com/jaredwray/cacheable)\n\n# cache-manager \n[![codecov](https://codecov.io/gh/jaredwray/cacheable/graph/badge.svg?token=lWZ9OBQ7GM)](https://codecov.io/gh/jaredwray/cacheable)\n[![tests](https://github.com/jaredwray/cacheable/actions/workflows/tests.yml/badge.svg)](https://github.com/jaredwray/cacheable/actions/workflows/tests.yml)\n[![license](https://img.shields.io/github/license/jaredwray/cacheable)](https://github.com/jaredwray/cacheable/blob/main/LICENSE)\n[![npm](https://img.shields.io/npm/dm/cache-manager)](https://npmjs.com/package/cache-manager)\n![npm](https://img.shields.io/npm/v/cache-manager)\n\n# Flexible NodeJS cache module\n\nA cache module for nodejs that allows easy wrapping of functions in cache, tiered caches, and a consistent interface. This module is now part of the [Cacheable](https://cacheable.org) project.\n\n## Table of Contents\n* [Features](#features)\n* [Installation](#installation)\n* [Usage Examples](#usage-examples)\n  * [Single Store](#single-store)\n  * [Multi-Store](#multi-store)\n  * [Cache Manager Options](#cache-manager-options)\n  * [Refresh cache keys in background](#refresh-cache-keys-in-background)\n  * [Error Handling](#error-handling)\n  * [Express Middleware](#express-middleware)\n  * [Store Engines](#store-engines)\n* [Contribute](#contribute)\n* [License](#license)\n\n## Features\n\n- Made with Typescript and compatible with [ESModules](https://nodejs.org/docs/latest-v14.x/api/esm.html)\n- Easy way to wrap any function in cache.\n- Tiered caches -- data gets stored in each cache and fetched from the highest.\n  priority cache(s) first.\n- Use any cache you want, as long as it has the same API.\n- 100% test coverage via [vitest](https://github.com/vitest-dev/vitest).\n\n## Installation\n\n    pnpm install cache-manager\n\n## Usage Examples\n\n### Single Store\n\n```typescript\nimport { caching } from 'cache-manager';\n\nconst memoryCache = await caching('memory', {\n  max: 100,\n  ttl: 10 * 1000 /*milliseconds*/,\n});\n\nconst ttl = 5 * 1000; /*milliseconds*/\nawait memoryCache.set('foo', 'bar', ttl);\n\nconsole.log(await memoryCache.get('foo'));\n// >> \"bar\"\n\nawait memoryCache.del('foo');\n\nconsole.log(await memoryCache.get('foo'));\n// >> undefined\n\nconst getUser = (id: string) => new Promise.resolve({ id: id, name: 'Bob' });\n\nconst userId = 123;\nconst key = 'user_' + userId;\n\nconsole.log(await memoryCache.wrap(key, () => getUser(userId), ttl));\n// >> { id: 123, name: 'Bob' }\n```\n\nSee unit tests in [`test/caching.test.ts`](./test/caching.test.ts) for more information.\n\n#### Example setting/getting several keys with mset() and mget()\n\n```typescript\nawait memoryCache.store.mset(\n  [\n    ['foo', 'bar'],\n    ['foo2', 'bar2'],\n  ],\n  ttl,\n);\n\nconsole.log(await memoryCache.store.mget('foo', 'foo2'));\n// >> ['bar', 'bar2']\n\n// Delete keys with mdel() passing arguments...\nawait memoryCache.store.mdel('foo', 'foo2');\n```\n\n#### Custom Stores\n\nYou can use your own custom store by creating one with the same API as the built-in memory stores.\n\n- [Example Custom Store lru-cache](https://github.com/jaredwray/cacheable/blob/main/packages/cache-manager/src/stores/memory.ts)\n- [Example Custom Store redis](https://github.com/jaredwray/cacheable/tree/main/packages/cache-manager-redis-yet)\n- [Example Custom Store ioredis](https://github.com/jaredwray/cacheable/tree/main/packages/cache-manager-ioredis-yet)\n\n#### Create single cache store synchronously\n\nAs `caching()` requires async functionality to resolve some stores, this is not well-suited to use for default function/constructor parameters etc.\n\nIf you need to create a cache store synchronously, you can instead use `createCache()`:\n\n```typescript\nimport { createCache, memoryStore } from 'cache-manager';\n\n// Create memory cache synchronously\nconst memoryCache = createCache(memoryStore({\n  max: 100,\n  ttl: 10 * 1000 /*milliseconds*/,\n}));\n\n// Default parameter in function\nfunction myService(cache = createCache(memoryStore())) {}\n\n// Default parameter in class constructor\nconst DEFAULT_CACHE = createCache(memoryStore(), { ttl: 60 * 1000 });\n// ...\nclass MyService {\n  constructor(private cache = DEFAULT_CACHE) {}\n}\n```\n\n### Multi-Store\n\n```typescript\nimport { multiCaching } from 'cache-manager';\n\nconst multiCache = multiCaching([memoryCache, someOtherCache]);\nconst userId2 = 456;\nconst key2 = 'user_' + userId;\nconst ttl = 5;\n\n// Sets in all caches.\nawait multiCache.set('foo2', 'bar2', ttl);\n\n// Fetches from highest priority cache that has the key.\nconsole.log(await multiCache.get('foo2'));\n// >> \"bar2\"\n\n// Delete from all caches\nawait multiCache.del('foo2');\n\n// Sets multiple keys in all caches.\n// You can pass as many key, value tuples as you want\nawait multiCache.mset(\n  [\n    ['foo', 'bar'],\n    ['foo2', 'bar2'],\n  ],\n  ttl\n);\n\n// mget() fetches from highest priority cache.\n// If the first cache does not return all the keys,\n// the next cache is fetched with the keys that were not found.\n// This is done recursively until either:\n// - all have been found\n// - all caches has been fetched\nconsole.log(await multiCache.mget('key', 'key2'));\n// >> ['bar', 'bar2']\n\n// Delete keys with mdel() passing arguments...\nawait multiCache.mdel('foo', 'foo2');\n```\n\nSee unit tests in [`test/multi-caching.test.ts`](./test/multi-caching.test.ts) for more information.\n\n### Cache Manager Options\n\nThe `caching` function accepts an options object as the second parameter. The following options are available:\n* ttl: The time to live in milliseconds. This is the maximum amount of time that an item can be in the cache before it is removed.\n* refreshThreshold: discussed in details below.\n* isCacheable: a function to determine whether the value is cacheable or not.\n* onBackgroundRefreshError: a function to handle errors that occur during background refresh.\n\n```typescript\nimport { caching } from 'cache-manager';\n\nconst memoryCache = await caching('memory', {\n  max: 100,\n  ttl: 10 * 1000 /*milliseconds*/,\n  shouldCloneBeforeSet: false, // this is set true by default (optional)\n});\n```\n\nWhen creating a memory store, you also get these addition options:\n* max: The maximum number of items that can be stored in the cache. If the cache is full, the least recently used item is removed.\n* shouldCloneBeforeSet: If true, the value will be cloned before being set in the cache. This is set to `true` by default.\n\n### Refresh cache keys in background\n\nBoth the `caching` and `multicaching` modules support a mechanism to refresh expiring cache keys in background when using the `wrap` function.  \nThis is done by adding a `refreshThreshold` attribute while creating the caching store or passing it to the `wrap` function.\n\nIf `refreshThreshold` is set and after retrieving a value from cache the TTL will be checked.  \nIf the remaining TTL is less than `refreshThreshold`, the system will update the value asynchronously,  \nfollowing same rules as standard fetching. In the meantime, the system will return the old value until expiration.\n\nNOTES:\n\n* In case of multicaching, the store that will be checked for refresh is the one where the key will be found first (highest priority).\n* If the threshold is low and the worker function is slow, the key may expire and you may encounter a racing condition with updating values.\n* The background refresh mechanism currently does not support providing multiple keys to `wrap` function.\n* If no `ttl` is set for the key, the refresh mechanism will not be triggered. For redis, the `ttl` is set to -1 by default.\n\nFor example, pass the refreshThreshold to `caching` like this:\n\n```typescript\nconst memoryCache = await caching('memory', {\n  max: 100,\n  ttl: 10 * 1000 /*milliseconds*/,\n  refreshThreshold: 3 * 1000 /*milliseconds*/,\n  \n  /* optional, but if not set, background refresh error will be an unhandled\n   * promise rejection, which might crash your node process */\n  onBackgroundRefreshError: (error) => { /* log or otherwise handle error */ }\n});\n```\n\nWhen a value will be retrieved from Redis with a TTL minor than 3sec, the value will be updated in the background.\n\n## Error Handling\n\n`multiCaching` now does not throw errors by default. Instead, all errors are evented through the `error` event. Here is an example on how to use it:\n\n```javascript\nconst multicache = await multiCaching([memoryCache, someOtherCache]);\nmulticache.on('error', (error) => {\n  console.error('Cache error:', error);\n});\n```\n\n## Using non-blocking set with wrap\nBy default, when using `wrap` the value is set in the cache before the function returns. \nWhile this behaviour can prevent additional calls to downstream resources, it can also slow down the response time.\nThis can be changed by setting the `nonBlockingSet` option to `true`. \nDoing will make the function return before the value is set in the cache.\nThe setting applies to both single and multi caches. \n\n```typescript\ncache.wrap('key', () => fetchValue(), 1000, 500, {nonBlockingSet: true});\n```\n\n## Express Middleware\n\nThis example sets up an Express application with a caching mechanism using cache-manager. The cacheMiddleware checks if the response for a request is already cached and returns it if available. If not, it proceeds to the route handler, caches the response, and then returns it. This helps to reduce the load on the server by avoiding repeated processing of the same requests.\n\n```typescript\n// The code imports the necessary modules using ES module syntax:\nimport { caching } from 'cache-manager';\nimport express from 'express';\n\n// The memory cache is initialized using cache-manager with a maximum of 100 items and a TTL (time-to-live) of 10 seconds:\nconst memoryCache = await caching('memory', {\n  max: 100,\n  ttl: 10 * 1000 /*milliseconds*/\n});\n\nconst app = express();\nconst port = 3000;\n\n// A middleware function is defined to check the cache before processing the request. If the response is found in the cache, it is returned immediately. If not, the request proceeds to the route handler, and the response is cached before being sent:\nconst cacheMiddleware = async (req, res, next) => {\n  const key = req.originalUrl;\n\n  try {\n    const cachedResponse = await memoryCache.get(key);\n    if (cachedResponse) {\n      // Cache hit, return the cached response\n      return res.send(cachedResponse);\n    } else {\n      // Cache miss, proceed to the route handler\n      res.sendResponse = res.send;\n      res.send = async (body) => {\n        // Store the response in cache\n        await memoryCache.set(key, body);\n        res.sendResponse(body);\n      };\n      next();\n    }\n  } catch (err) {\n    next(err);\n  }\n};\n\n// The cacheMiddleware is applied to the /data route, which simulates a slow database call with a 2-second delay:\napp.get('/data', cacheMiddleware, (req, res) => {\n  // Simulate a slow database call\n  setTimeout(() => {\n    res.send({ data: 'This is some data', timestamp: new Date() });\n  }, 2000); // 2 seconds delay\n});\n\napp.listen(port, () => {\n  console.log(`Server is running on http://localhost:${port}`);\n});\n\n```\n\n## Store Engines\n\n### Official and updated to last version\n\n- [node-cache-manager-redis-yet](https://github.com/jaredwray/cacheable/packages/cache-manager-redis-yet) (uses [node_redis](https://github.com/NodeRedis/node_redis))\n\n- [node-cache-manager-ioredis-yet](https://github.com/jaredwray/cacheable/packages/cache-manager-ioredis-yet) (uses [ioredis](https://github.com/luin/ioredis))\n\n### Third party\n\n- [node-cache-manager-redis](https://github.com/dial-once/node-cache-manager-redis) (uses [sol-redis-pool](https://github.com/joshuah/sol-redis-pool))\n\n- [node-cache-manager-redis-store](https://github.com/dabroek/node-cache-manager-redis-store) (uses [node_redis](https://github.com/NodeRedis/node_redis))\n\n- [node-cache-manager-ioredis](https://github.com/Tirke/node-cache-manager-ioredis) (uses [ioredis](https://github.com/luin/ioredis))\n\n- [node-cache-manager-mongodb](https://github.com/v4l3r10/node-cache-manager-mongodb)\n\n- [node-cache-manager-mongoose](https://github.com/disjunction/node-cache-manager-mongoose)\n\n- [node-cache-manager-fs-binary](https://github.com/sheershoff/node-cache-manager-fs-binary)\n\n- [node-cache-manager-fs-hash](https://github.com/rolandstarke/node-cache-manager-fs-hash)\n\n- [node-cache-manager-hazelcast](https://github.com/marudor/node-cache-manager-hazelcast)\n\n- [node-cache-manager-memcached-store](https://github.com/theogravity/node-cache-manager-memcached-store)\n\n- [node-cache-manager-memory-store](https://github.com/theogravity/node-cache-manager-memory-store)\n\n- [node-cache-manager-couchbase](https://github.com/davidepellegatta/node-cache-manager-couchbase)\n\n- [node-cache-manager-sqlite](https://github.com/maxpert/node-cache-manager-sqlite)\n\n- [@resolid/cache-manager-sqlite](https://github.com/huijiewei/cache-manager-sqlite) (uses [better-sqlite3](https://github.com/WiseLibs/better-sqlite3))\n\n## Contribute\n\nIf you would like to contribute to the project, please read how to contribute here [CONTRIBUTING.md](./CONTRIBUTING.md).\n\n## License\n\ncache-manager is licensed under the [MIT license](./LICENSE).\n",
    "licenseText": "MIT License\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to\ndeal in the Software without restriction, including without limitation the\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\nsell copies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\nDEALINGS IN THE SOFTWARE.\n"
  },
  "artifacts": [],
  "remote": {
    "resolved": "https://registry.yarnpkg.com/cache-manager/-/cache-manager-5.7.6.tgz#bdd8a154c73e5233824aa09ceb359ed225d37b7e",
    "type": "tarball",
    "reference": "https://registry.yarnpkg.com/cache-manager/-/cache-manager-5.7.6.tgz",
    "hash": "bdd8a154c73e5233824aa09ceb359ed225d37b7e",
    "integrity": "sha512-wBxnBHjDxF1RXpHCBD6HGvKER003Ts7IIm0CHpggliHzN1RZditb7rXoduE1rplc2DEFYKxhLKgFuchXMJje9w==",
    "registry": "npm",
    "packageName": "cache-manager",
    "cacheIntegrity": "sha512-wBxnBHjDxF1RXpHCBD6HGvKER003Ts7IIm0CHpggliHzN1RZditb7rXoduE1rplc2DEFYKxhLKgFuchXMJje9w== sha1-vdihVMc+UjOCSqCc6zWe0iXTe34="
  },
  "registry": "npm",
  "hash": "bdd8a154c73e5233824aa09ceb359ed225d37b7e"
}